{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import math\n",
    "import pickle\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 4.813804388046265\n",
      "(1600000, 2)\n",
      "(359, 2)\n"
     ]
    }
   ],
   "source": [
    "tweets=[]\n",
    "start= time.time()\n",
    "train_data= pd.read_csv('data/training.csv',names = ['Type' , 'id', 'date', 'query','user', 'tweet'], encoding='latin-1')\n",
    "test_data= pd.read_csv('data/test.csv',names = ['Type' , 'id', 'date', 'query','user', 'tweet'], encoding='latin-1')\n",
    "test_data = test_data.drop(['id','date','query','user'], axis=1)\n",
    "train_data= train_data.drop(['id','date','query','user'], axis=1)\n",
    "test_data = test_data.drop(test_data[test_data['Type']==2].index)\n",
    "# print(train_data[:5])\n",
    "# print(train_data[:5])\n",
    "print('time',time.time()-start)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 2)\n",
      "(359, 2)\n",
      "                                                  words  word_count\n",
      "Type                                                               \n",
      "0     [@switchfoot, http://twitpic, com/2y1zl, -, Aw...          20\n",
      "0     [is, upset, that, he, can't, update, his, Face...          21\n",
      "0     [@Kenichan, I, dived, many, times, for, the, b...          18\n",
      "0     [my, whole, body, feels, itchy, and, like, its...          10\n",
      "0     [@nationwideclass, no, it's, not, behaving, at...          21\n"
     ]
    }
   ],
   "source": [
    "tweets = train_data.set_index('Type')\n",
    "tweets['words']= tweets['tweet'].str.replace(',',' ').str.replace('.', ' ').str.split()\n",
    "tweets['word_count']= tweets['words'].str.len()\n",
    "tweets = tweets.drop(['tweet'], axis=1)\n",
    "\n",
    "# tweets_test = test_data.set_index('Type')\n",
    "tweets_test=test_data\n",
    "tweets_test['words']= tweets_test['tweet'].str.replace(',',' ').str.replace('.', ' ').str.split()\n",
    "tweets_test['word_count']= tweets_test ['words'].str.len()\n",
    "tweets_test = tweets_test.set_index('Type')\n",
    "tweets_test = tweets_test.drop(['tweet'], axis=1)\n",
    "print(tweets.shape)\n",
    "print(tweets_test.shape)\n",
    "print(tweets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(tweets):\n",
    "    vocab = {}\n",
    "    for l_words in tweets['words']:\n",
    "        for word in l_words:\n",
    "            vocab[word] =1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(tweets,vocab):\n",
    "    phi_neg = (tweets_neg.shape[0]+1)/(tweets.shape[0] +2)\n",
    "    phi_pos =(tweets_pos.shape[0]+1)/(tweets.shape[0]+2)\n",
    "        \n",
    "    dict_neg_words={}\n",
    "    dict_neg_words=vocab.copy()\n",
    "    \n",
    "    for l_words in tweets_neg['words']:\n",
    "        for word in l_words:\n",
    "                dict_neg_words[word] +=1\n",
    "    \n",
    "    dict_pos_words={}\n",
    "    dict_pos_words=vocab.copy()\n",
    "    for l_words in tweets_pos['words']:\n",
    "        for word in l_words:\n",
    "            dict_pos_words[word] +=1\n",
    "    return dict_neg_words, dict_pos_words, phi_neg, phi_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10962723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10345074"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(12040935-1078212)\n",
    "11423286-1078212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(y, y_pred):\n",
    "    correct =0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]:\n",
    "            correct +=1\n",
    "    return correct/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes():   \n",
    "    count=0\n",
    "    correct =0\n",
    "    total_words_neg = tweets_neg['word_count'].sum()\n",
    "    total_words_pos = tweets_pos['word_count'].sum()\n",
    "    total_words_vocab = len(vocab)\n",
    "    print(total_words_neg)\n",
    "    print(total_words_vocab)\n",
    "    for word in vocab:\n",
    "        theta_neg[word]= dict_neg_words[word] /(total_words_neg+total_words_vocab)\n",
    "        theta_pos[word]= dict_pos_words[word] /(total_words_pos + total_words_vocab)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(tweets):\n",
    "    tweets_neg=tweets.loc[[0]]\n",
    "    tweets_pos=tweets.loc[[4]]\n",
    "    total_words_neg = tweets_neg['word_count'].sum()\n",
    "    total_words_pos = tweets_pos['word_count'].sum()\n",
    "    total_words_vocab = len(vocab)\n",
    "    temp_n = math.log(1/(total_words_neg+total_words_vocab))\n",
    "    temp_p = math.log(1/(total_words_pos + total_words_vocab))\n",
    "    correct =0\n",
    "    for tweet in tweets_neg['words']:\n",
    "        prob_y_neg =0\n",
    "        prob_y_pos =0\n",
    "        for word in tweet:\n",
    "            if word in vocab:\n",
    "                prob_y_neg += math.log(theta_neg[word])\n",
    "                prob_y_pos += math.log(theta_pos[word])\n",
    "            else :\n",
    "                prob_y_pos += temp_p\n",
    "                prob_y_neg += temp_n\n",
    "        prob_y_neg += math.log(phi_neg)\n",
    "        prob_y_pos += math.log(phi_pos)\n",
    "        if(prob_y_neg > prob_y_pos):\n",
    "            correct += 1\n",
    "    print(correct) \n",
    "    correct_neg = correct\n",
    "        \n",
    "    for tweet in tweets_pos['words']:\n",
    "        prob_y_neg =0\n",
    "        prob_y_pos =0\n",
    "        for word in tweet:\n",
    "            if word in theta_neg:\n",
    "                prob_y_neg += math.log(theta_neg[word])\n",
    "                prob_y_pos += math.log(theta_pos[word])\n",
    "            else :\n",
    "                prob_y_pos += temp_p\n",
    "                prob_y_neg += temp_n\n",
    "        prob_y_neg += math.log(phi_neg)\n",
    "        prob_y_pos += math.log(phi_pos)\n",
    "        if(prob_y_neg < prob_y_pos):\n",
    "            correct += 1   \n",
    "    correct_pos = correct- correct_neg       \n",
    "    print(correct_pos)\n",
    "    print('accuray ',correct/tweets.shape[0])\n",
    "    return correct_neg, correct_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10962673\n",
      "1078262\n",
      "9.789448261260986\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "tweets_neg=tweets.loc[[0]]\n",
    "tweets_pos=tweets.loc[[4]]\n",
    "vocab = create_vocab(tweets)\n",
    "dict_neg_words, dict_pos_words, phi_neg, phi_pos= create_dict(tweets,vocab)\n",
    "theta_neg={}\n",
    "theta_pos={}\n",
    "naive_bayes()\n",
    "print(time.time()-start)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in theta_neg:\n",
    "#     print(key, theta_neg[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712613\n",
      "646313\n",
      "accuray  0.84932875\n",
      "time 15.832371950149536\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "check_accuracy(tweets)\n",
    "print('time', time.time()- start)\n",
    "print('Done')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "148\n",
      "accuray  0.807799442896936\n",
      "0.006784200668334961\n",
      "                                                  words  word_count\n",
      "Type                                                               \n",
      "0     [Monday, already, Iran, may, implode, Kitchen,...          22\n",
      "4     [getting, ready, to, test, out, some, burger, ...          20\n",
      "4     [i, lam, so, in, love, with, Bobby, Flay, he, ...          26\n",
      "0     [I, just, created, my, first, LaTeX, file, fro...          22\n",
      "4     [using, Linux, and, loving, it, -, so, much, n...          19\n",
      "4     [After, using, LaTeX, a, lot, any, other, type...          12\n",
      "0     [On, that, note, I, hate, Word, I, hate, Pages...          27\n",
      "4     [Ahhh, back, in, a, *real*, text, editing, env...          11\n",
      "0     [Trouble, in, Iran, I, see, Hmm, Iran, Iran, s...          12\n",
      "0     [Reading, the, tweets, coming, out, of, Iran, ...          15\n"
     ]
    }
   ],
   "source": [
    "total_neg_test = tweets_test.loc[[0]].shape[0]\n",
    "total_pos_test = tweets_test.loc[[4]].shape[0]\n",
    "start = time.time()\n",
    "correct_neg, correct_pos = check_accuracy(tweets_test)\n",
    "print(time.time()-start)\n",
    "print(tweets_test[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "wrong_neg = total_neg_test-correct_neg\n",
    "wrong_pos = total_pos_test-correct_pos\n",
    "con_mat = pd.DataFrame([[correct_neg, wrong_pos],[wrong_neg, correct_pos]], columns=['neg_actual', 'pos_actual'], index=['neg_pred', 'pos_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          neg_actual  pos_actual\n",
      "neg_pred         142          34\n",
      "pos_pred          35         148\n"
     ]
    }
   ],
   "source": [
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)  Random Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pred():\n",
    "    correct =0\n",
    "    for ind in tweets_test.index:\n",
    "        temp = randint(0,1)\n",
    "        if temp ==1:\n",
    "            temp =4\n",
    "        if(ind == temp):\n",
    "            correct += 1\n",
    "#             print(ind, temp)\n",
    "    print(correct)\n",
    "    print('accuracy ', correct/tweets_test.shape[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "accuracy  0.5264623955431755\n"
     ]
    }
   ],
   "source": [
    "random_pred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5069637883008357\n"
     ]
    }
   ],
   "source": [
    "correct =0\n",
    "for ind in tweets_test.index:\n",
    "    maj =4\n",
    "    if tweets_neg.shape[0] > tweets_pos.shape[0]:\n",
    "        maj = tweets_neg.shape[0]\n",
    "    if(maj == ind):\n",
    "        correct+=1\n",
    "print(correct/tweets_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.(d) stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = train_data\n",
    "# print(t.shape[0])\n",
    "# start = time.time()\n",
    "# t['words']=(t['tweet'].str.lower()).map(word_tokenize)\n",
    "# # tweets['word_count']= tweets['words'].str.len()\n",
    "# # tweets = tweets.drop(['tweet'], axis=1)\n",
    "# print(time.time()- start)\n",
    "# print(t[:12])\n",
    "# print('Done')\n",
    "# t = t.drop(['tweet'], axis=1)\n",
    "# t.to_pickle('df_tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(str):\n",
    "    temp= str.lower().replace(',',' ').replace('.',' ').split()\n",
    "    res =[stemming.stem(word) for word in temp if word not in stop_words and '@' not in word]        \n",
    "    return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.01471519470215\n",
      "Done\n",
      "                                                  words  word_count\n",
      "Type                                                               \n",
      "0     [http://twitpic, com/2y1zl, -, awww, that', bu...          13\n",
      "0     [upset, can't, updat, facebook, text, might, c...          12\n",
      "0     [dive, mani, time, ball, manag, save, 50%, res...          10\n",
      "0                [whole, bodi, feel, itchi, like, fire]           6\n",
      "0                  [behav, i'm, mad, here?, can't, see]           6\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "tweets = train_data.set_index('Type')\n",
    "start = time.time()\n",
    "tweets['words']= tweets['tweet'].map(sep)\n",
    "tweets['word_count']= tweets['words'].str.len()\n",
    "tweets = tweets.drop(['tweet'], axis=1)\n",
    "print(time.time()-start)\n",
    "print('Done')\n",
    "print(tweets[:5])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6138839\n",
      "545693\n",
      "6.948061227798462\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "tweets_neg=tweets.loc[[0]]\n",
    "tweets_pos=tweets.loc[[4]]\n",
    "vocab = create_vocab(tweets)\n",
    "dict_neg_words={}\n",
    "dict_pos_words={}\n",
    "dict_neg_words, dict_pos_words, phi_neg, phi_pos= create_dict(tweets,vocab)\n",
    "theta_neg={}\n",
    "theta_pos={}\n",
    "naive_bayes()\n",
    "print(time.time()-start)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663939\n",
      "626842\n",
      "accuray  0.806738125\n",
      "time 10.596755027770996\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "check_accuracy(tweets)\n",
    "print('time', time.time()- start)\n",
    "print('Done')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07632899284362793\n"
     ]
    }
   ],
   "source": [
    "tweets_test = test_data.set_index('Type')\n",
    "start = time.time()\n",
    "tweets_test['words']= tweets_test['tweet'].map(sep)\n",
    "tweets_test['word_count']= tweets_test['words'].str.len()\n",
    "tweets_test = tweets_test.drop(['tweet'], axis=1)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "153\n",
      "accuray  0.8328690807799443\n",
      "0.01022481918334961\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "correct_neg, correct_pos = check_accuracy(tweets_test)\n",
    "print(time.time()-start)\n",
    "# print(tweets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list):\n",
    "    return ' '.join(list)\n",
    "\n",
    "tweets['tweet']= tweets['words'].map(merge)\n",
    "# print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "tfidfVectorizer=TfidfVectorizer(use_idf=True)\n",
    " \n",
    "tfidf_vectors=tfidfVectorizer.fit_transform(tweets['tweet'].tolist())\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 325212)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectors.shape)\n",
    "# print(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_data['Type'].toarray().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_model=GaussianNB()\n",
    "# for i in tqdm(range(0,1600000,1000),total=1600):\n",
    "#     X_small=tfidf_vectors[i:i+1000,:]\n",
    "#     nb_model.partial_fit(X_small.todense(),train_data[i:i+1000]['Type'].tolist(),[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "# pickle.dump(nb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = loaded_model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  words  word_count  \\\n",
      "Type                                                                  \n",
      "4     [loooooooovvvvvvee, kindle2, dx, cool, 2, fant...           7   \n",
      "4         [read, kindle2, love, lee, child, good, read]           7   \n",
      "4          [ok, first, asses, #kindle2, fuck, rocks!!!]           6   \n",
      "4     [love, kindle2, i'v, mine, month, never, look,...          15   \n",
      "4           [fair, enough, kindle2, think, perfect, :)]           6   \n",
      "\n",
      "                                                  tweet  \n",
      "Type                                                     \n",
      "4     loooooooovvvvvvee kindle2 dx cool 2 fantast right  \n",
      "4                 read kindle2 love lee child good read  \n",
      "4                 ok first asses #kindle2 fuck rocks!!!  \n",
      "4     love kindle2 i'v mine month never look back ne...  \n",
      "4                  fair enough kindle2 think perfect :)  \n"
     ]
    }
   ],
   "source": [
    "tweets_test['tweet']= tweets_test['words'].map(merge)\n",
    "print(tweets_test[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 325212)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectors_test=tfidfVectorizer.transform(tweets_test['tweet'].tolist())\n",
    "print(tfidf_vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = loaded_model.predict(tfidf_vectors_test.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4986072423398329"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_accuracy(list(tweets_test.index),pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
